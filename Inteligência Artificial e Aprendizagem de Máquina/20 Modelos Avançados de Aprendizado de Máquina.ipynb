{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modelos Avançados com Python\n",
    "\n",
    "As **redes neurais e modelos supervisionados avançados** são amplamente utilizados em problemas de **classificação, regressão e reconhecimento de padrões complexos**.\n",
    "\n",
    "Cada tipo de arquitetura possui **características específicas**, adequadas a determinados tipos de dados e objetivos.\n",
    "\n",
    "| Modelo | Ideal para | Tipo de Dados | Pontos Fortes |\n",
    "|:--|:--|:--|:--|\n",
    "| **DNN (Deep Neural Network)** | Dados tabulares e complexos | Numéricos e categóricos | Captura relações não lineares e interações entre variáveis |\n",
    "| **CNN (Convolutional Neural Network)** | Imagens, vídeos, sinais espaciais | Matriciais (pixels) | Capta padrões espaciais e visuais |\n",
    "| **RNN (Recurrent Neural Network)** | Séries temporais e textos | Sequenciais | Capta dependências temporais e contextuais |\n",
    "| **SVM (Support Vector Machine)** | Dados bem definidos e separáveis | Tabulares, numéricos | Eficiente em conjuntos menores e alta dimensionalidade |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d6198",
   "metadata": {},
   "source": [
    "## DNN — Redes Neurais Profundas\n",
    "\n",
    "As **Deep Neural Networks (DNNs)** são compostas por **múltiplas camadas ocultas** de neurônios artificiais, permitindo a modelagem de **relações altamente não lineares**.\n",
    "\n",
    "Cada camada aprende **representações progressivamente mais abstratas** dos dados de entrada.\n",
    "\n",
    "**Vantagens:**\n",
    "- Excelente desempenho em dados tabulares e numéricos.  \n",
    "- Aprende relações complexas entre variáveis.  \n",
    "- Flexível e de fácil implementação com frameworks como TensorFlow e Keras.\n",
    "\n",
    "**Limitações:**\n",
    "- Pode superajustar (overfitting) se os dados forem poucos.  \n",
    "- Requer normalização e ajuste de hiperparâmetros.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo Prático — Classificação de Câncer (Dataset: Breast Cancer)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carrega dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Padronização\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criação da DNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilação e treinamento\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=16, verbose=1)\n",
    "\n",
    "# Avaliação\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55367d",
   "metadata": {},
   "source": [
    "## CNN — Redes Neurais Convolucionais\n",
    "\n",
    "\n",
    "As **Convolutional Neural Networks (CNNs)** são projetadas para trabalhar com dados que possuem **estrutura espacial**, como imagens ou vídeos.  \n",
    "Utilizam **camadas convolucionais** que aplicam **filtros (kernels)** para detectar padrões locais (bordas, texturas, formas).\n",
    "\n",
    "**Componentes principais:**\n",
    "- **Camada Convolucional:** extrai padrões locais.  \n",
    "- **Camada de Pooling:** reduz a dimensionalidade e mantém características relevantes.  \n",
    "- **Camada densa final:** realiza a classificação.\n",
    "\n",
    "**Vantagens:**\n",
    "- Reconhece padrões invariantes de posição.  \n",
    "- Reduz a necessidade de engenharia manual de características.  \n",
    "- Escalável e amplamente usada em visão computacional.\n",
    "\n",
    "**Limitações:**\n",
    "- Requer mais recursos computacionais.  \n",
    "- Necessita grande volume de dados.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação de Dígitos (MNIST)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normaliza e ajusta formato\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Criação da CNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilação e treinamento\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Avaliação\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Acurácia no teste:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14ae86",
   "metadata": {},
   "source": [
    "## RNN — Redes Neurais Recorrentes\n",
    "\n",
    "As **RNNs (Recurrent Neural Networks)** foram projetadas para processar **dados sequenciais**, onde a ordem das entradas é importante (ex.: séries temporais, textos).  \n",
    "Elas possuem **conexões recorrentes** que permitem reter **informações anteriores** (memória).\n",
    "\n",
    "**Variações comuns:**\n",
    "- **LSTM (Long Short-Term Memory):** evita o problema de gradiente desaparecendo.  \n",
    "- **GRU (Gated Recurrent Unit):** mais leve e eficiente que LSTM.\n",
    "\n",
    "**Vantagens:**\n",
    "- Captura dependências temporais.  \n",
    "- Ideal para previsões em séries temporais e textos.\n",
    "\n",
    "**Limitações:**\n",
    "- Treinamento mais lento.  \n",
    "- Dificuldade com dependências de longo prazo (parcialmente resolvido com LSTM/GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão de Série Temporal Sintética\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Geração de série temporal\n",
    "time = np.arange(0, 200, 0.1)\n",
    "data = np.sin(time) + 0.1 * np.random.randn(len(time))\n",
    "\n",
    "# Normaliza\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.reshape(-1,1))\n",
    "\n",
    "# Cria janelas (sequências)\n",
    "def create_dataset(data, step=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-step):\n",
    "        X.append(data[i:i+step])\n",
    "        y.append(data[i+step])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_dataset(data_scaled, step=20)\n",
    "X_train, y_train = X[:1500], y[:1500]\n",
    "X_test, y_test = X[1500:], y[1500:]\n",
    "\n",
    "# Criação da RNN LSTM\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, activation='tanh', input_shape=(20,1)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, verbose=1)\n",
    "\n",
    "# Avaliação\n",
    "pred = model.predict(X_test)\n",
    "plt.plot(y_test, label='Real')\n",
    "plt.plot(pred, label='Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc1b51",
   "metadata": {},
   "source": [
    "## SVM — Máquinas de Vetores de Suporte\n",
    "\n",
    "O **SVM (Support Vector Machine)** busca um **hiperplano ótimo** que separa as classes com **máxima margem**.  \n",
    "Trabalha bem mesmo em **alta dimensionalidade**, utilizando **funções kernel** para transformar dados não lineares em um espaço separável.\n",
    "\n",
    "**Principais kernels:**\n",
    "- Linear  \n",
    "- Polinomial (`poly`)  \n",
    "- Radial Basis Function (`rbf`)  \n",
    "\n",
    "**Vantagens:**\n",
    "- Eficiente em conjuntos pequenos e bem estruturados.  \n",
    "- Alta precisão com ajustes adequados.\n",
    "\n",
    "**Limitações:**\n",
    "- Custo computacional alto para datasets grandes.  \n",
    "- Difícil ajuste de hiperparâmetros `C` e `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação no Iris Dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=iris.target_names).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b1337",
   "metadata": {},
   "source": [
    "## Exercícios Propostos\n",
    "\n",
    "1. **DNN:**  \n",
    "   - Aplique a rede ao dataset *Wine* (sklearn).  \n",
    "   - Teste 2, 3 e 4 camadas ocultas.  \n",
    "   - Compare tempo e acurácia.\n",
    "\n",
    "2. **CNN:**  \n",
    "   - Use o dataset *CIFAR-10*.  \n",
    "   - Compare o desempenho alterando filtros e camadas.\n",
    "\n",
    "3. **RNN:**  \n",
    "   - Gere uma série temporal com tendência crescente.  \n",
    "   - Compare desempenho de LSTM vs GRU.\n",
    "\n",
    "4. **SVM:**  \n",
    "   - Compare os kernels `'linear'`, `'poly'` e `'rbf'`.  \n",
    "   - Explique visualmente o impacto do parâmetro `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01e5ab",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "| Modelo | Melhor uso | Complexidade | Vantagens |\n",
    "|:--|:--|:--|:--|\n",
    "| **DNN** | Dados tabulares | Média | Flexível e adaptável |\n",
    "| **CNN** | Imagens | Alta | Extração automática de padrões visuais |\n",
    "| **RNN** | Séries temporais | Alta | Capta dependências temporais |\n",
    "| **SVM** | Dados estruturados pequenos | Média | Alta precisão com poucos dados |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Material_CNN_DNN_RNN_SVM.ipynb"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
