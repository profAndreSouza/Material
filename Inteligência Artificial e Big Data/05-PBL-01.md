## 1 Importando bibliotecas essenciais

```python
import pandas as pd
```

Carrega o **pandas** e d√° o apelido `pd`. Pandas √© a base para manipular
dados tabulares (DataFrame): ler CSV/Excel, filtrar, agrupar, agregar
etc.

```python
import numpy as np
```

Carrega o **NumPy** como `np`. √â o pacote de vetores/matrizes e
opera√ß√µes num√©ricas de alta performance. Muitas libs (pandas,
scikit-learn) usam NumPy por baixo.

```python
import matplotlib.pyplot as plt
```

Importa o m√≥dulo de **plot** do Matplotlib como `plt`. Serve para criar
gr√°ficos (linhas, barras, histos, scatter, etc.). √â a base de
visualiza√ß√£o "low-level".

```python
import seaborn as sns
```

Importa o **Seaborn**, camada "high-level" sobre o Matplotlib que
facilita gr√°ficos estat√≠sticos (countplot, heatmap, boxplot...) com
estilos agrad√°veis.

```python
from sklearn.model_selection import train_test_split
```

Traz a fun√ß√£o **train_test_split** do scikit-learn. Divide os dados em
**treino** e **teste** de forma aleat√≥ria (e pode estratificar) para
avaliar o modelo sem vi√©s.

```python
from sklearn.preprocessing import StandardScaler, LabelEncoder
```

Importa dois **pr√©-processadores**:

- `StandardScaler`: padroniza features num√©ricas (m√©dia 0, desvio 1).
  √ötil para modelos sens√≠veis a escala (ex.: regress√£o log√≠stica,
  SVM).
- `LabelEncoder`: transforma r√≥tulos **categ√≥ricos** em inteiros (ex.:
  "Brasil"‚Üí0, "UK"‚Üí1). Use com cuidado: para **features** categ√≥ricas
  com v√°rias categorias o usual √© **One-Hot**; `LabelEncoder` √© bom
  para **alvos** ou categorias ordinais.

```python
from sklearn.linear_model import LogisticRegression
```

Importa o estimador **Regress√£o Log√≠stica** (classificador linear para
problemas bin√°rios/multiclasse). Retorna probabilidades e √©
interpret√°vel via coeficientes.

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
```

Traz m√©tricas de avalia√ß√£o:

- `accuracy_score`: propor√ß√£o de acertos.
- `precision_score`: entre os positivos previstos, quantos s√£o
  corretos.
- `recall_score`: entre os positivos reais, quantos foram encontrados.
- `f1_score`: m√©dia harm√¥nica de precis√£o e recall (equil√≠brio).
- `confusion_matrix`: tabela VP/VN/FP/FN.
- `classification_report`: resumo com precis√£o/recall/F1 por classe.

```python
sns.set(style="whitegrid")
```

Configura o **estilo** padr√£o dos gr√°ficos Seaborn/Matplotlib para
"whitegrid" (fundo branco com grade discreta). Melhora a legibilidade
sem precisar estilizar cada gr√°fico.

## 2 Carregando o dataset

```python
url = "https://github.com/profAndreSouza/Material/raw/main/Intelig%C3%AAncia%20Artificial%20e%20Big%20Data/Online%20Retail.xlsx"
```

Aqui voc√™ guarda em `url` o **link direto para o arquivo Excel**
hospedado no GitHub. ‚ö†Ô∏è Importante: usamos o `raw` na URL para baixar o
arquivo diretamente, sem a p√°gina HTML do GitHub.

```python
data = pd.read_excel(url, engine='openpyxl')
```

- `pd.read_excel(...)`: fun√ß√£o do pandas para ler arquivos `.xls` ou
  `.xlsx`.
- `url`: caminho remoto ou local do arquivo (no caso, o link GitHub).
- `engine='openpyxl'`: especifica o motor de leitura do Excel
  (necess√°rio para `.xlsx`).

üëâ O resultado √© armazenado no DataFrame `data`, que passa a conter
todas as transa√ß√µes do varejo online (colunas como `InvoiceNo`,
`StockCode`, `Description`, `Quantity`, `InvoiceDate`, `UnitPrice`,
`CustomerID`, `Country`).

## 3 Limpeza de dados

Coment√°rio para marcar a se√ß√£o de **data cleaning**, ou seja, prepara√ß√£o
inicial para garantir qualidade dos dados antes da an√°lise/modelagem.

```python
# Removendo registros sem CustomerID
data_clean = data.dropna(subset=['CustomerID'])
```

- O dataset tem transa√ß√µes onde a coluna `CustomerID` est√° vazia (ex.:
  compras sem cliente identificado).
- `dropna(subset=['CustomerID'])` elimina apenas as linhas em que
  `CustomerID` √© **NaN**.
- O novo DataFrame `data_clean` s√≥ mant√©m registros com cliente
  conhecido.

```python
# Removendo transa√ß√µes com quantidade <= 0 ou UnitPrice <= 0
data_clean = data_clean[(data_clean['Quantity'] > 0) & (data_clean['UnitPrice'] > 0)]
```

- Alguns registros t√™m quantidade negativa (ex.: devolu√ß√µes) ou pre√ßo
  zero (ex.: erro no cadastro, brindes).
- Esse filtro garante que ficam apenas as compras **v√°lidas**
  (quantidade positiva e pre√ßo positivo).
- Usa uma condi√ß√£o booleana com `&` (E l√≥gico) para filtrar.

```python
# Criando vari√°vel TotalPrice
data_clean['TotalPrice'] = data_clean['Quantity'] * data_clean['UnitPrice']
```

- Cria uma nova coluna **`TotalPrice`** para cada linha (transa√ß√£o).
- Multiplica `Quantity` (quantidade comprada) por `UnitPrice` (pre√ßo
  unit√°rio).
- Representa o **valor total gasto** pelo cliente naquela compra.

üëâ Resultado at√© aqui: um DataFrame _limpo e enriquecido_ (data_clean)
pronto para gerar indicadores de clientes.

## 4 Feature Engineering

Se√ß√£o dedicada a criar **vari√°veis derivadas** que representem melhor o
comportamento do cliente.

```python
snapshot_date = data_clean['InvoiceDate'].max() + pd.Timedelta(days=1)
```

- `data_clean['InvoiceDate'].max()` ‚Üí pega a √∫ltima data de compra
  registrada no dataset.
- `+ pd.Timedelta(days=1)` ‚Üí soma 1 dia, criando um "ponto de
  refer√™ncia" (**snapshot**) para calcular o **tempo desde a √∫ltima
  compra** (Recency).
- Isso √© comum em RFM (Recency, Frequency, Monetary).

```python
# Agrupando por cliente
features = data_clean.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency
    'InvoiceNo': 'count',                                      # Frequency
    'TotalPrice': ['sum', 'mean'],                             # Monetary total e m√©dio
    'Quantity': ['sum', 'mean'],                               # Quantidade total e m√©dia
    'StockCode': 'nunique',                                    # Diversidade de produtos
    'Country': 'first'                                         # Pa√≠s do cliente
})
```

üîé o que acontece aqui:

- `groupby('CustomerID')`: agrupa todas as transa√ß√µes por cliente.
- `.agg({...})`: aplica diferentes fun√ß√µes em diferentes colunas.

colunas criadas:

- **Recency** ‚Üí diferen√ßa entre `snapshot_date` e a data da √∫ltima
  compra (`x.max()`).
- **Frequency** ‚Üí n√∫mero de faturas (`InvoiceNo`) por cliente.
- **MonetarySum** ‚Üí gasto total (`TotalPrice.sum()`).
- **MonetaryMean** ‚Üí gasto m√©dio por compra (`TotalPrice.mean()`).
- **QuantitySum** ‚Üí quantidade total de itens comprados.
- **QuantityMean** ‚Üí m√©dia de itens por compra.
- **ProductDiversity** ‚Üí n√∫mero de produtos √∫nicos
  (`StockCode.nunique()`).
- **Country** ‚Üí pa√≠s do cliente (como todos os registros do cliente
  t√™m o mesmo pa√≠s, pega o `first`).

```python
# Ajustando nomes das colunas
features.columns = ['Recency', 'Frequency', 'MonetarySum', 'MonetaryMean',
                    'QuantitySum', 'QuantityMean', 'ProductDiversity', 'Country']
```

- Depois do `.agg`, as colunas ficam com nomes compostos (ex:
  `TotalPrice_sum`, `Quantity_mean`).
- Aqui, renomeamos de forma mais clara e direta.

```python
# Codificando pa√≠s
features['Country'] = LabelEncoder().fit_transform(features['Country'])
```

- Converte a coluna categ√≥rica `Country` em n√∫meros inteiros (ex:
  UK=0, Germany=1, France=2...).
- Necess√°rio porque modelos de machine learning trabalham melhor com
  valores num√©ricos.

üëâ Agora `features` √© uma tabela **com uma linha por cliente**, j√°
transformada em vari√°veis num√©ricas que descrevem seu comportamento de
compra.

## 5 Criando vari√°vel alvo

```python
# Usando RFM para definir "Champions"
quantiles = features[['Recency', 'Frequency', 'MonetarySum']].quantile([0.25, 0.5, 0.75]).to_dict()
```

- Pegamos os **quartis (25%, 50%, 75%)** de **Recency**, **Frequency**
  e **MonetarySum**.

- Exemplo: se a mediana (50%) da frequ√™ncia for 10, sabemos que metade
  dos clientes comprou mais de 10 vezes.

- `.to_dict()` ‚Üí transforma em dicion√°rio para acesso r√°pido.

  - Estrutura fica assim:

    ```python
    {
      'Recency': {0.25: valor1, 0.5: valor2, 0.75: valor3},
      'Frequency': {...},
      'MonetarySum': {...}
    }
    ```

```python
def rfm_score(x, quantiles, col, reverse=False):
    if reverse:  # menor recency √© melhor
        if x <= quantiles[col][0.25]:
            return 4
        elif x <= quantiles[col][0.5]:
            return 3
        elif x <= quantiles[col][0.75]:
            return 2
        else:
            return 1
    else:
        if x <= quantiles[col][0.25]:
            return 1
        elif x <= quantiles[col][0.5]:
            return 2
        elif x <= quantiles[col][0.75]:
            return 3
        else:
            return 4
```

Essa fun√ß√£o gera uma **nota de 1 a 4** para cada cliente, dependendo de
onde ele est√° nos quartis.

- `reverse=True`: caso especial para **Recency**, porque aqui **quanto
  menor, melhor** (√∫ltima compra mais recente).

  - Recency baixo ‚Üí Score alto (4).

- Para Frequency e Monetary, o contr√°rio: **quanto maior, melhor**.

  - Valores baixos ‚Üí Score baixo (1).

```python
features['RecencyScore'] = features['Recency'].apply(rfm_score, args=(quantiles, 'Recency', True))
features['FrequencyScore'] = features['Frequency'].apply(rfm_score, args=(quantiles, 'Frequency', False))
features['MonetaryScore'] = features['MonetarySum'].apply(rfm_score, args=(quantiles, 'MonetarySum', False))
```

- Cria tr√™s novas colunas com os scores de cada dimens√£o RFM.

Exemplo:

- Recency = 5 dias ‚Üí `RecencyScore = 4`
- Frequency = 20 compras ‚Üí `FrequencyScore = 3`
- Monetary = 2000 libras ‚Üí `MonetaryScore = 4`

```python
features['RFMScore'] = (
    features['RecencyScore'].astype(str) +
    features['FrequencyScore'].astype(str) +
    features['MonetaryScore'].astype(str)
)
```

- Junta os tr√™s scores em uma string.
- Exemplo: Recency=4, Frequency=3, Monetary=4 ‚Üí `RFMScore = "434"`.

```python
features['Champions'] = (features['RFMScore'] == '444').astype(int)  # clientes top RFM
```

- Define como **alvo (target)** os clientes que s√£o **tops em todas as
  m√©tricas (Recency=4, Frequency=4, Monetary=4)**.
- `== '444'` retorna True/False ‚Üí `.astype(int)` transforma em 1
  (campe√£o) ou 0 (n√£o campe√£o).

üëâ Resultado: agora temos uma vari√°vel bin√°ria (`Champions`) que serve
de **vari√°vel dependente (y)** para treinar o modelo preditivo.

## 6 Prepara√ß√£o para modelagem

```python
X = features[['Recency', 'Frequency', 'MonetarySum', 'MonetaryMean',
              'QuantitySum', 'QuantityMean', 'ProductDiversity', 'Country']]
y = features['Champions']
```

- **X** = as vari√°veis independentes (features preditoras).

  - Pegamos 8 colunas: rec√™ncia, frequ√™ncia, monet√°rio, quantidade
    etc.
  - S√£o as informa√ß√µes de comportamento do cliente.

- **y** = vari√°vel dependente (alvo).

  - `Champions` ‚Üí 1 se cliente √© campe√£o, 0 caso contr√°rio.

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```

- Divide o dataset em **treino (70%)** e **teste (30%)**.
- `random_state=42`: garante reprodutibilidade (mesmos dados em cada
  execu√ß√£o).
- `stratify=y`: preserva a propor√ß√£o de **0s e 1s** no treino e teste,
  evitando desbalanceamento.

Exemplo:

- Se tivermos 10% de campe√µes no dataset, tanto no treino quanto no
  teste manteremos aproximadamente essa propor√ß√£o.

```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

- Aqui normalizamos os dados para **m√©dia 0 e desvio padr√£o 1**.

- Isso √© importante porque:

  - Vari√°veis como `MonetarySum` podem estar na casa dos milhares,
    enquanto `Recency` est√° em dias.
  - O modelo poderia dar peso maior √†s vari√°veis com valores
    grandes.

- `fit_transform` no treino ‚Üí aprende os par√¢metros (m√©dia e desvio) e
  aplica a transforma√ß√£o.

- `transform` no teste ‚Üí aplica a **mesma transforma√ß√£o** sem
  recalcular.

üëâ agora temos:

- `X_train_scaled` e `y_train` ‚Üí usados para treinar o modelo.
- `X_test_scaled` e `y_test` ‚Üí usados para avaliar a performance.

## 7 Constru√ß√£o do modelo de Regress√£o Log√≠stica

```python
model = LogisticRegression(max_iter=1000)
```

- criamos um objeto `LogisticRegression`, que √© um algoritmo de
  **classifica√ß√£o bin√°ria**.

- o par√¢metro `max_iter=1000` define o n√∫mero m√°ximo de itera√ß√µes que
  o otimizador pode rodar at√© convergir.

  - por padr√£o √© 100, mas como nossos dados podem ser mais
    complexos, aumentamos para 1000 para evitar erros de
    _convergence warning_.

```python
model.fit(X_train_scaled, y_train)
```

- treinamos o modelo nos dados de treino.
- o algoritmo encontra os **pesos (coeficientes)** das vari√°veis
  preditoras que melhor separam os clientes **campe√µes (1)** dos
  **n√£o-campe√µes (0)**.
- basicamente, ele est√° ajustando uma "fun√ß√£o log√≠stica" que calcula a
  probabilidade de cada cliente ser **campe√£o**.

üîé depois dessa etapa, o modelo j√° sabe reconhecer padr√µes nos dados de
clientes.

üëâ pr√≥ximo passo natural √© **avaliar a performance** no conjunto de
teste (`X_test_scaled, y_test`) usando m√©tricas como acur√°cia, precis√£o,
recall e F1-score.

## 8 Avalia√ß√£o do modelo

```python
y_pred = model.predict(X_test_scaled)
```

- `model.predict(...)` retorna os **r√≥tulos preditos** (0 ou 1) para
  cada amostra de `X_test_scaled`.
- `y_pred` √© um array com as classes previstas pelo modelo (classe
  mais prov√°vel segundo o limiar padr√£o 0.5).
- Observa√ß√£o: se voc√™ quiser **probabilidades** ao inv√©s de r√≥tulos,
  use `model.predict_proba(X_test_scaled)` (√∫til para ajustar limiar).

```python
print(f"Acur√°cia: {accuracy_score(y_test, y_pred):.3f}")
```

- `accuracy_score(y_true, y_pred)` calcula a **propor√ß√£o de previs√µes
  corretas** (todos os acertos / total).
- `:.3f` √© apenas formata√ß√£o --- imprime o n√∫mero com 3 casas
  decimais.

```python
print(f"Precis√£o: {precision_score(y_test, y_pred):.3f}")
```

- `precision_score` = entre as observa√ß√µes que o modelo previu como
  positivas (1), **quantas realmente eram positivas**.
- Interpreta√ß√£o: alta precis√£o ‚Üí poucas previs√µes positivas falsas (FP
  baixos). Importante quando custo de um falso positivo √© alto.

```python
print(f"Recall: {recall_score(y_test, y_pred):.3f}")
```

- `recall_score` (sensibilidade) = entre as observa√ß√µes realmente
  positivas, **quantas o modelo conseguiu identificar**.
- Interpreta√ß√£o: alto recall ‚Üí poucos falsos negativos (FN baixos).
  Importante quando √© cr√≠tico encontrar todos os positivos (ex.:
  fraude).

```python
print(f"F1-score: {f1_score(y_test, y_pred):.3f}")
```

- `f1_score` √© a **m√©dia harm√¥nica** entre precis√£o e recall. √ötil
  quando voc√™ quer um balan√ßo entre os dois (especialmente com classes
  desbalanceadas).

```python
cm = confusion_matrix(y_test, y_pred)
```

- `confusion_matrix` retorna uma matriz 2x2 com contagens:

      [[TN, FP],
       [FN, TP]]

  onde:

  - TN = verdadeiros negativos (0 previstos como 0)
  - FP = falsos positivos (0 previstos como 1)
  - FN = falsos negativos (1 previstos como 0)
  - TP = verdadeiros positivos (1 previstos como 1)

```python
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['N√£o', 'Sim'], yticklabels=['N√£o', 'Sim'])
```

- Plota a matriz de confus√£o com Seaborn:

  - `annot=True` escreve os n√∫meros dentro das c√©lulas.
  - `fmt='d'` formata os n√∫meros como inteiros.
  - `cmap='Blues'` escolhe o mapa de cores.
  - `xticklabels`/`yticklabels` definem os r√≥tulos das
    colunas/linhas (aqui mapeando 0‚Üí"N√£o", 1‚Üí"Sim").

- **Aten√ß√£o**: a ordem dos r√≥tulos corresponde √† ordem natural das
  classes (0,1). Verifique se seu `y_test` usa exatamente esses
  valores.

```python
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o')
plt.show()
```

- `xlabel`/`ylabel`/`title` colocam r√≥tulos e t√≠tulo no gr√°fico.
- `plt.show()` exibe o gr√°fico no notebook.

```python
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred))
```

- `classification_report` imprime, por classe (0 e 1), as m√©tricas:
  **precision, recall, f1-score** e **support** (quantidade de
  exemplos reais daquela classe).
- Tamb√©m mostra m√©dias (macro avg, weighted avg), √∫teis para avalia√ß√£o
  geral considerando desbalanceamento.

### Observa√ß√µes pr√°ticas (curtas, importantes)

- Se `Champions` for **muito raro** (muito desbalanceado),
  **acur√°cia** pode enganar --- prefira `precision`, `recall`, `f1` ou
  `ROC AUC`.

- Para ver probabilidades e ajustar limiar:

  ```python
  probs = model.predict_proba(X_test_scaled)[:,1]  # probabilidade da classe 1
  ```

  e ent√£o testar thresholds diferentes (`probs >= 0.4`, etc.).

- Em dados desbalanceados, considere `class_weight='balanced'` em
  `LogisticRegression` ou t√©cnicas como **oversampling (SMOTE)** /
  **undersampling**.

- Para avaliar separa√ß√£o geral das classes, calcule a **ROC AUC** com
  `sklearn.metrics.roc_auc_score(y_test, probs)` e plote a curva ROC.

## 9 Import√¢ncia das vari√°veis

```python
coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Coef': model.coef_[0]
}).sort_values(by='Coef', ascending=False)
```

üîé O que est√° acontecendo:

1.  `model.coef_` ‚Üí matriz com os **coeficientes** da regress√£o
    log√≠stica.

    - Dimens√£o: `(1, n_features)` porque temos uma √∫nica vari√°vel alvo
      bin√°ria.
    - `model.coef_[0]` extrai o vetor com os coeficientes.

2.  `X.columns` ‚Üí lista com os nomes das vari√°veis originais usadas no
    modelo.

3.  `pd.DataFrame({...})` cria um DataFrame com duas colunas:

    - `"Feature"` ‚Üí nome da vari√°vel
    - `"Coef"` ‚Üí valor do coeficiente correspondente

4.  `.sort_values(by='Coef', ascending=False)` ‚Üí ordena da vari√°vel com
    maior coeficiente para menor.

‚öñÔ∏è **Interpreta√ß√£o dos coeficientes**:

- Os coeficientes da regress√£o log√≠stica representam o **impacto no
  log-odds** de ser Champion (classe 1) quando a vari√°vel aumenta **1
  unidade padronizada** (j√° que voc√™ aplicou `StandardScaler`).

- Sinal:

  - **Coef \> 0** ‚Üí aumenta a probabilidade de ser Champion.
  - **Coef \< 0** ‚Üí diminui a probabilidade.

- Magnitude:

  - Quanto mais distante de zero, maior a influ√™ncia.

```python
print("Impacto das vari√°veis na probabilidade de ser Champion:")
print(coefficients)
```

- Apenas imprime o DataFrame ordenado.
- Isso mostra **quais vari√°veis mais puxam o cliente para ser Champion
  ou n√£o**.

‚ú® Dicas para enriquecer a an√°lise:

1.  Converter coeficientes em **odds ratio**:

    ```python
    coefficients['OddsRatio'] = np.exp(coefficients['Coef'])
    ```

    - Odds Ratio \> 1 ‚Üí aumenta chance de Champion.
    - Odds Ratio \< 1 ‚Üí reduz chance.

2.  Visualizar em gr√°fico de barras:

    ```python
    sns.barplot(x='Coef', y='Feature', data=coefficients, palette="coolwarm")
    plt.title("Import√¢ncia das vari√°veis (Coeficientes)")
    plt.show()
    ```
